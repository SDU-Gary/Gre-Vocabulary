#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
GREå•è¯æ¨é€è„šæœ¬ - æœ€ç»ˆä¿®å¤ç‰ˆæœ¬
è§£å†³ntfy.shä¸­æ–‡ç¼–ç é—®é¢˜çš„ç»ˆææ–¹æ¡ˆ
"""

import csv
import requests
import random
import time
import json
from datetime import date, timedelta, datetime
from safe_csv import get_csv_handler

# --- é…ç½®åŒº ---
NTFY_TOPIC = "gre-words-for-my-awesome-life-123xyz"
CSV_FILE_PATH = "/root/gre_word_pusher/words.csv"
WORDS_PER_PUSH = 15

# --- è‰¾å®¾æµ©æ–¯è®°å¿†æ›²çº¿é—´éš” (å¤©) ---
REVIEW_INTERVALS = [1, 2, 4, 7, 15, 30, 60]


def load_config():
    """ä»ç¯å¢ƒå˜é‡æ–‡ä»¶åŠ è½½é…ç½®"""
    global NTFY_TOPIC, CSV_FILE_PATH, WORDS_PER_PUSH
    
    try:
        import os
        # å°è¯•ä»ç¯å¢ƒå˜é‡è¯»å–
        NTFY_TOPIC = os.getenv('NTFY_TOPIC', NTFY_TOPIC)
        CSV_FILE_PATH = os.getenv('GRE_CSV_PATH', CSV_FILE_PATH)
        
        # å°è¯•ä».envæ–‡ä»¶è¯»å–
        env_file = '/root/gre_word_pusher/.env'
        if os.path.exists(env_file):
            with open(env_file, 'r', encoding='utf-8') as f:
                for line in f:
                    line = line.strip()
                    if line.startswith('NTFY_TOPIC='):
                        NTFY_TOPIC = line.split('=', 1)[1].strip()
                    elif line.startswith('GRE_CSV_PATH='):
                        CSV_FILE_PATH = line.split('=', 1)[1].strip()
                    elif line.startswith('WORDS_PER_PUSH='):
                        try:
                            WORDS_PER_PUSH = int(line.split('=', 1)[1].strip())
                        except ValueError:
                            pass
        
        print(f"ğŸ“‹ é…ç½®åŠ è½½å®Œæˆ:")
        print(f"   NTFYä¸»é¢˜: {NTFY_TOPIC}")
        print(f"   CSVè·¯å¾„: {CSV_FILE_PATH}")
        print(f"   æ¨é€æ•°é‡: {WORDS_PER_PUSH}")
        
    except Exception as e:
        print(f"âš ï¸ é…ç½®åŠ è½½å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å€¼: {e}")


def get_review_words(file_path, num_words):
    """
    åŸºäºè‰¾å®¾æµ©æ–¯è®°å¿†æ›²çº¿æŒ‘é€‰å•è¯ã€‚
    ä¼˜å…ˆçº§: 1. æ–°è¯ (review_count=0)  2. åˆ°è¾¾å¤ä¹ æ—¥æœŸçš„è¯
    ä½¿ç”¨å®‰å…¨çš„æ–‡ä»¶æ“ä½œ
    """
    csv_handler = get_csv_handler(file_path)
    all_words = csv_handler.read_all_words()
    
    if not all_words:
        print("ğŸ“ CSVæ–‡ä»¶ä¸ºç©ºæˆ–ä¸å­˜åœ¨")
        return [], [], set()

    today = date.today()
    due_words = []
    
    # 1. ç­›é€‰å‡ºæ‰€æœ‰æ–°è¯å’Œåˆ°æœŸçš„è¯
    for i, row in enumerate(all_words):
        try:
            if len(row) < 5:
                print(f"âš ï¸ è·³è¿‡æ ¼å¼ä¸å®Œæ•´çš„è¡Œ {i+1}: {row}")
                continue
                
            word, definition, added_date, last_reviewed_date, review_count_str = row
            review_count = int(review_count_str)
            
            # ä¼˜å…ˆå¤„ç†æ–°è¯ 
            if review_count == 0:
                due_words.append((row, -999, i))  # ç”¨-999ä¿è¯æ–°è¯æ’åºæœ€å‰
                continue

            # è®¡ç®—ä¸‹ä¸€æ¬¡å¤ä¹ æ—¥æœŸ
            try:
                last_review_dt = datetime.strptime(last_reviewed_date, '%Y-%m-%d').date()
            except ValueError:
                print(f"âš ï¸ è·³è¿‡æ—¥æœŸæ ¼å¼é”™è¯¯çš„è¡Œ {i+1}: {row}")
                continue
                
            # è·å–å½“å‰é˜¶æ®µå¯¹åº”çš„é—´éš”å¤©æ•°
            interval_days = REVIEW_INTERVALS[min(review_count, len(REVIEW_INTERVALS) - 1)]
            next_review_date = last_review_dt + timedelta(days=interval_days)

            if today >= next_review_date:
                days_overdue = (today - next_review_date).days
                due_words.append((row, days_overdue, i))  # è®°å½•åŸå§‹ç´¢å¼•
                
        except (ValueError, IndexError) as e:
            print(f"âš ï¸ è·³è¿‡æ ¼å¼é”™è¯¯çš„è¡Œ {i+1}: {row}. é”™è¯¯: {e}")
            continue

    # 2. æ’åºï¼šæœ€é€¾æœŸçš„ > æ–°è¯ > åˆšåˆ°æœŸçš„
    due_words.sort(key=lambda x: x[1], reverse=True)
    
    # 3. æå–è¦å¤ä¹ çš„å•è¯åˆ—è¡¨å’Œå®ƒä»¬çš„åŸå§‹ç´¢å¼•
    words_to_review_with_indices = due_words[:num_words]
    words_to_review = [item[0] for item in words_to_review_with_indices]
    original_indices = {item[2] for item in words_to_review_with_indices}

    return words_to_review, all_words, original_indices


def send_notification_simple_json(topic, words_to_review, max_retries=3):
    """
    ä½¿ç”¨ç®€åŒ–çš„JSONæ ¼å¼æ¨é€ï¼ˆé€‚é…ntfy.sh APIè¦æ±‚ï¼‰
    """
    if not words_to_review:
        print("ğŸ“­ æ²¡æœ‰éœ€è¦å¤ä¹ çš„å•è¯ã€‚")
        return False

    # æ„å»ºæ¶ˆæ¯å†…å®¹
    message_lines = []
    for i, word_data in enumerate(words_to_review, 1):
        if len(word_data) >= 2:
            word, definition = word_data[0], word_data[1]
            message_lines.append(f"{i}. {word}: {definition}")
    
    if not message_lines:
        print("âŒ æ²¡æœ‰æœ‰æ•ˆçš„å•è¯æ•°æ®")
        return False
        
    message = "\n".join(message_lines)
    message += f"\n\nğŸ“š å…±{len(words_to_review)}ä¸ªå•è¯"
    message += "\nğŸ’¡ è‰¾å®¾æµ©æ–¯è®°å¿†æ›²çº¿æ¨é€"
    
    for attempt in range(max_retries):
        try:
            # æ–¹æ³•1: ä½¿ç”¨æ­£ç¡®çš„JSONæ ¼å¼
            payload = {
                "topic": topic,
                "message": message,
                "title": f"ğŸ§  GREå•è¯å¤ä¹  ({len(words_to_review)}è¯)"
            }
            
            response = requests.post(
                "https://ntfy.sh/",
                data=json.dumps(payload),
                headers={
                    "Content-Type": "application/json"
                },
                timeout=15
            )
            
            if response.status_code == 200:
                print(f"âœ… æˆåŠŸå‘é€ {len(words_to_review)} ä¸ªå•è¯åˆ° ntfy (ç®€åŒ–JSON)")
                return True
            else:
                print(f"âŒ ç®€åŒ–JSONæ¨é€å¤±è´¥: {response.status_code}")
                print(f"å“åº”: {response.text}")
                
        except Exception as e:
            print(f"âŒ ç®€åŒ–JSONæ¨é€å¼‚å¸¸ (å°è¯• {attempt + 1}/{max_retries}): {e}")
            if attempt < max_retries - 1:
                time.sleep(1)
    
    return False


def send_notification_encoded_post(topic, words_to_review, max_retries=3):
    """
    ä½¿ç”¨ç¼–ç åçš„POSTæ–¹æ³•æ¨é€
    """
    if not words_to_review:
        return False

    # æ„å»ºæ¶ˆæ¯å†…å®¹
    message_lines = []
    for i, word_data in enumerate(words_to_review, 1):
        if len(word_data) >= 2:
            word, definition = word_data[0], word_data[1]
            message_lines.append(f"{i}. {word}: {definition}")
    
    if not message_lines:
        return False
        
    message = "\n".join(message_lines)
    message += f"\n\nğŸ“š å…±{len(words_to_review)}ä¸ªå•è¯"
    
    for attempt in range(max_retries):
        try:
            # ç›´æ¥å‘é€UTF-8ç¼–ç çš„å­—èŠ‚æ•°æ®
            response = requests.post(
                f"https://ntfy.sh/{topic}",
                data=message.encode('utf-8'),
                headers={
                    "Title": f"GREå•è¯å¤ä¹  ({len(words_to_review)}è¯)".encode('utf-8').decode('latin-1'),
                    "Priority": "default"
                },
                timeout=15
            )
            
            if response.status_code == 200:
                print(f"âœ… æˆåŠŸå‘é€ {len(words_to_review)} ä¸ªå•è¯åˆ° ntfy (ç¼–ç POST)")
                return True
            else:
                print(f"âŒ ç¼–ç POSTæ¨é€å¤±è´¥: {response.status_code}")
                
        except Exception as e:
            print(f"âŒ ç¼–ç POSTæ¨é€å¼‚å¸¸ (å°è¯• {attempt + 1}/{max_retries}): {e}")
            if attempt < max_retries - 1:
                time.sleep(1)
    
    return False


def send_notification_english_fallback(topic, words_to_review, max_retries=3):
    """
    è‹±æ–‡é™çº§æ¨é€æ–¹æ¡ˆ
    """
    if not words_to_review:
        return False

    # åˆ›å»ºè‹±æ–‡æ ¼å¼æ¶ˆæ¯
    message_lines = []
    for i, word_data in enumerate(words_to_review, 1):
        if len(word_data) >= 2:
            word, definition = word_data[0], word_data[1]
            # åªä¿ç•™è‹±æ–‡å•è¯ï¼Œé¿å…ä¸­æ–‡ç¼–ç é—®é¢˜
            message_lines.append(f"{i}. {word}")
    
    if not message_lines:
        return False
        
    message = f"GRE Words Review ({len(words_to_review)} words):\n\n"
    message += "\n".join(message_lines)
    message += "\n\nCheck your study app for Chinese definitions."
    
    for attempt in range(max_retries):
        try:
            response = requests.post(
                f"https://ntfy.sh/{topic}",
                data=message,
                headers={
                    "Title": f"GRE Review - {len(words_to_review)} words",
                    "Priority": "high",
                    "Tags": "brain,study,gre"
                },
                timeout=15
            )
            
            if response.status_code == 200:
                print(f"âœ… æˆåŠŸå‘é€ {len(words_to_review)} ä¸ªå•è¯åˆ° ntfy (è‹±æ–‡æ ¼å¼)")
                return True
            else:
                print(f"âŒ è‹±æ–‡æ¨é€å¤±è´¥: {response.status_code}")
                
        except Exception as e:
            print(f"âŒ è‹±æ–‡æ¨é€å¼‚å¸¸ (å°è¯• {attempt + 1}/{max_retries}): {e}")
            if attempt < max_retries - 1:
                time.sleep(1)
    
    return False


def send_notification_with_retry(topic, words_to_review, max_retries=3):
    """
    æ™ºèƒ½æ¨é€ï¼šå°è¯•å¤šç§æ–¹æ³•ï¼Œç¡®ä¿æ¨é€æˆåŠŸ
    """
    if not words_to_review:
        print("ğŸ“­ æ²¡æœ‰éœ€è¦å¤ä¹ çš„å•è¯ã€‚")
        return False
        
    print(f"ğŸ“± å¼€å§‹æ¨é€ {len(words_to_review)} ä¸ªå•è¯...")
    
    # æ–¹æ³•1: å°è¯•ç®€åŒ–JSONæ ¼å¼æ¨é€
    print("ğŸ”„ å°è¯•ç®€åŒ–JSONæ ¼å¼æ¨é€...")
    if send_notification_simple_json(topic, words_to_review, 2):
        return True
    
    # æ–¹æ³•2: å°è¯•ç¼–ç POSTæ¨é€
    print("ğŸ”„ JSONå¤±è´¥ï¼Œå°è¯•ç¼–ç POSTæ¨é€...")
    if send_notification_encoded_post(topic, words_to_review, 2):
        return True
    
    # æ–¹æ³•3: é™çº§åˆ°è‹±æ–‡æ ¼å¼æ¨é€
    print("ğŸ”„ ç¼–ç POSTå¤±è´¥ï¼Œé™çº§åˆ°è‹±æ–‡æ¨é€...")
    if send_notification_english_fallback(topic, words_to_review, 2):
        return True
    
    # æ–¹æ³•4: è®°å½•å¤±è´¥æ—¥å¿—
    print("âŒ æ‰€æœ‰æ¨é€æ–¹æ³•éƒ½å¤±è´¥äº†")
    log_failed_notification(words_to_review)
    return False


def update_and_save_words(file_path, all_words, reviewed_indices):
    """
    æ›´æ–°å¤ä¹ è¿‡çš„å•è¯çš„çŠ¶æ€å¹¶å®‰å…¨å†™å›æ–‡ä»¶
    ä½¿ç”¨å¤‡ä»½æœºåˆ¶é˜²æ­¢æ•°æ®æŸå
    """
    if not reviewed_indices:
        return
        
    today_str = date.today().isoformat()
    updated_count = 0
    
    for i, row in enumerate(all_words):
        if i in reviewed_indices and len(row) >= 5:
            row[3] = today_str  # æ›´æ–°ä¸Šæ¬¡å¤ä¹ æ—¥æœŸ
            row[4] = str(int(row[4]) + 1)  # è®°å¿†é˜¶æ®µ+1
            updated_count += 1
    
    csv_handler = get_csv_handler(file_path)
    try:
        csv_handler.write_all_words(all_words, create_backup=True)
        print(f"âœ… æˆåŠŸæ›´æ–° {updated_count} ä¸ªå•è¯çš„å¤ä¹ çŠ¶æ€")
    except Exception as e:
        print(f"âŒ æ›´æ–°å•è¯çŠ¶æ€å¤±è´¥: {e}")


def log_failed_notification(words_to_review):
    """è®°å½•æ¨é€å¤±è´¥çš„å•è¯ï¼Œä¾›åç»­é‡è¯•"""
    try:
        timestamp = datetime.now().isoformat()
        failed_log_path = CSV_FILE_PATH.replace('.csv', '_failed_notifications.log')
        
        with open(failed_log_path, 'a', encoding='utf-8') as f:
            f.write(f"\n--- {timestamp} ---\n")
            for word_data in words_to_review:
                if len(word_data) >= 2:
                    f.write(f"{word_data[0]}: {word_data[1]}\n")
            f.write("--- End ---\n")
        
        print(f"ğŸ“ å¤±è´¥çš„æ¨é€å·²è®°å½•åˆ°: {failed_log_path}")
    except Exception as e:
        print(f"âŒ è®°å½•å¤±è´¥æ—¥å¿—æ—¶å‡ºé”™: {e}")


if __name__ == "__main__":
    print("="*50)
    print("ğŸš€ GREå•è¯æ¨é€ç³»ç»Ÿå¯åŠ¨ - æœ€ç»ˆä¿®å¤ç‰ˆ")
    print(f"â° æ‰§è¡Œæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("="*50)
    
    try:
        # 1. åŠ è½½é…ç½®
        load_config()
        
        # 2. è·å–éœ€è¦å¤ä¹ çš„å•è¯
        print("\nğŸ“š åˆ†æéœ€è¦å¤ä¹ çš„å•è¯...")
        review_list, all_data, reviewed_idx = get_review_words(CSV_FILE_PATH, WORDS_PER_PUSH)
        
        if review_list:
            print(f"ğŸ“‹ æ‰¾åˆ° {len(review_list)} ä¸ªéœ€è¦å¤ä¹ çš„å•è¯:")
            for i, word_data in enumerate(review_list[:5], 1):  # æ˜¾ç¤ºå‰5ä¸ª
                if len(word_data) >= 2:
                    print(f"   {i}. {word_data[0]}: {word_data[1]}")
            if len(review_list) > 5:
                print(f"   ... è¿˜æœ‰ {len(review_list)-5} ä¸ªå•è¯")
            
            # 3. å‘é€æ¨é€
            success = send_notification_with_retry(NTFY_TOPIC, review_list)
            
            # 4. æ›´æ–°å¤ä¹ çŠ¶æ€
            if success:
                update_and_save_words(CSV_FILE_PATH, all_data, reviewed_idx)
                print("âœ… æ¨é€æˆåŠŸï¼Œå•è¯çŠ¶æ€å·²æ›´æ–°")
            else:
                print("âŒ ç”±äºæ¨é€å¤±è´¥ï¼Œæœªæ›´æ–°å•è¯çŠ¶æ€")
        else:
            print("ğŸ“­ ä»Šå¤©æ²¡æœ‰éœ€è¦å¤ä¹ çš„å•è¯")
            
    except Exception as e:
        print(f"âŒ è„šæœ¬æ‰§è¡Œå‡ºé”™: {e}")
        import traceback
        traceback.print_exc()
    
    print("\n" + "="*50)
    print(f"ğŸ ä»»åŠ¡å®Œæˆ: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("="*50)